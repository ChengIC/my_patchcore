{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80203515",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference_utils import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "from matplotlib.pyplot import figure\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80f38a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "annotation_dir = '/Users/rc/Documents/GitHub/my_patchcore/datasets/full_body/Annotations'\n",
    "def getBBox(img_id):\n",
    "    xml_filePath = os.path.join (annotation_dir, img_id + '.xml')\n",
    "    xml_file = open(xml_filePath, encoding='UTF-8')\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    for obj in root.iter('object'):\n",
    "        cls = obj.find('name').text\n",
    "        bboxes = []\n",
    "        if cls != 'HUMAN':\n",
    "            xmlbox = obj.find('bndbox')\n",
    "            xmin = int(xmlbox.find('xmin').text)\n",
    "            xmax = int(xmlbox.find('xmax').text)\n",
    "            ymin = int(xmlbox.find('ymin').text)\n",
    "            ymax = int(xmlbox.find('ymax').text)\n",
    "            single_box = {\n",
    "                    'xmin':xmin,\n",
    "                    'xmax':xmax,\n",
    "                    'ymin':ymin,\n",
    "                    'ymax':ymax,\n",
    "            }\n",
    "            bboxes.append(single_box)\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91596ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def renderFeatureMap(pxl_lvl_anom_score):\n",
    "    score_range = pxl_lvl_anom_score.min(), pxl_lvl_anom_score.max()\n",
    "    fmap_img = pred_to_img(pxl_lvl_anom_score, score_range)\n",
    "    plt.imshow(fmap_img, cmap=\"jet\", alpha=0.5)\n",
    "    plt.axis('off')\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png', bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "    overlay_img = Image.open(buf)\n",
    "    return np.array(overlay_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e9bfd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_high(single_fmap):\n",
    "    count = (single_fmap>=0.8).sum()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "971291d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selected_fmap (all_feature_images):\n",
    "    energies = []\n",
    "    for single_fmap in all_feature_images:\n",
    "        energies.append(count_high(single_fmap))\n",
    "        \n",
    "    rank_list = [sorted(energies).index(x) for x in energies]\n",
    "\n",
    "    final_weighted_list = []\n",
    "    for r in rank_list:\n",
    "        if r == 0:\n",
    "            final_weighted_list.append(0.9)\n",
    "        else:\n",
    "            final_weighted_list.append(0.1/(len(rank_list)-1))\n",
    "    print (final_weighted_list)\n",
    "    \n",
    "    average_fmap = []\n",
    "    for idx, single_fmap in enumerate(all_feature_images):\n",
    "        if len(average_fmap)==0:\n",
    "            average_fmap = final_weighted_list[idx] * single_fmap\n",
    "        else:\n",
    "            average_fmap += final_weighted_list[idx] * single_fmap\n",
    "            \n",
    "    average_fmap = average_fmap/len(all_feature_images)\n",
    "    return average_fmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805b573f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use cpu for training or inference\n",
      "loading model dir: /Users/rc/Documents/GitHub/my_patchcore/FrontBackCore/exp/2022_07_07_09_29_48/models/MG9SY3ASH7B7_back sucessfully\n",
      "use cpu for training or inference\n",
      "loading model dir: /Users/rc/Documents/GitHub/my_patchcore/FrontBackCore/exp/2022_07_07_09_29_48/models/6UCFYVHKJS2D_front sucessfully\n",
      "use cpu for training or inference\n",
      "loading model dir: /Users/rc/Documents/GitHub/my_patchcore/FrontBackCore/exp/2022_07_07_09_29_48/models/9EPQMUVDMJMA_front sucessfully\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "img_list = os.listdir('/Users/rc/Documents/GitHub/my_patchcore/datasets/full_body/test/objs/')\n",
    "img_path = '/Users/rc/Documents/GitHub/my_patchcore/datasets/full_body/test/objs/' + random.choice(img_list)\n",
    "info = None\n",
    "if 'front' in img_path:\n",
    "    info = 'front'\n",
    "else:\n",
    "    info = 'back'\n",
    "\n",
    "model_dir = '/Users/rc/Documents/GitHub/my_patchcore/FrontBackCore/exp/2022_07_07_09_29_48/models'\n",
    "average_pixel_score = []\n",
    "all_feature_images = []\n",
    "for single_model in os.listdir(model_dir):\n",
    "    model_path = os.path.join(model_dir, single_model)\n",
    "    results = InferenceCore(model_path).inference_one_img(img_path)\n",
    "    all_feature_images.append(results['pixel_score'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c6f46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_fmap = selected_fmap(all_feature_images)\n",
    "avg_fmap = torch.tensor(avg_fmap)\n",
    "score_range = avg_fmap.min(), avg_fmap.max()\n",
    "fmap_img = pred_to_img(avg_fmap, score_range)\n",
    "figure(figsize=(10, 10), dpi=80)\n",
    "plt.imshow(fmap_img, cmap=\"jet\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27484d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fmap in all_feature_images:\n",
    "    figure()\n",
    "    fmap = torch.tensor(fmap)\n",
    "    plt.imshow(renderFeatureMap(fmap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d20f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_img = Image.open(img_path).convert('RGB')\n",
    "sample_img = cv2.imread(img_path)\n",
    "img_id = img_path.split('/')[-1].split('.jpg')[0]\n",
    "all_boxes = getBBox(img_id)\n",
    "\n",
    "for bb in all_boxes:\n",
    "    image = cv2.rectangle(sample_img, (bb['xmin'], bb['ymin']), (bb['xmax'], bb['ymax']), (0, 0, 255), 3)\n",
    "\n",
    "figure(figsize=(10, 10), dpi=80)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b8fcec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dc58f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ind",
   "language": "python",
   "name": "ind"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
